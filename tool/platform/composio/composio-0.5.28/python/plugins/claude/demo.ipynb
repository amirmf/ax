{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TextBlock(text=\"Hello! It's nice to meet you. How can I assist you today?\", type='text')]\n"
     ]
    }
   ],
   "source": [
    "import anthropic\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv(\"../../examples/.env\")\n",
    "\n",
    "client = anthropic.Anthropic(\n",
    "    # defaults to os.environ.get(\"ANTHROPIC_API_KEY\")\n",
    "    # api_key=\"my_api_key\",\n",
    ")\n",
    "message = client.messages.create(\n",
    "    model=\"claude-3-opus-20240229\",\n",
    "    max_tokens=1024,\n",
    "    messages=[{\"role\": \"user\", \"content\": \"Hello, Claude\"}],\n",
    ")\n",
    "print(message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sawradip/miniconda3/envs/composio-trial/lib/python3.11/site-packages/composio/sdk/sdk.py:344: UserWarning: Using all the actions of an app is not recommended. Please use tags to filter actions or provide specific actions. We just pass the important actions to the agent, but this is not meant to be used in production.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ToolsBetaMessage(id='msg_013yCJVvGvm2j4w7NQoiQLfp', content=[TextBlock(text='<thinking>\\nThe relevant tool to star a repository is github_star_repo. This function takes two required parameters:\\n\\nowner: The owner of the repository. The user provided this as \"sawradip\".\\nrepo: The name of the repository. The user provided this as \"sawradip\".\\n\\nSince the user directly provided values for both required parameters, we can proceed with calling the github_star_repo function.\\n</thinking>', type='text'), ToolUseBlock(id='toolu_01PKPV6wrQ3p3KpJxGSyfraM', input={'owner': 'sawradip', 'repo': 'sawradip'}, name='github_star_repo', type='tool_use')], model='claude-3-opus-20240229', role='assistant', stop_reason='tool_use', stop_sequence=None, type='message', usage=Usage(input_tokens=1561, output_tokens=166))\n"
     ]
    }
   ],
   "source": [
    "import anthropic\n",
    "from pprint import pprint\n",
    "\n",
    "client = anthropic.Anthropic()\n",
    "from composio import App\n",
    "from composio_claude import ComposioToolset\n",
    "\n",
    "toolset = ComposioToolset()\n",
    "composio_tools = toolset.get_tools(tools=App.GITHUB)\n",
    "# pprint(out)\n",
    "\n",
    "\n",
    "response = client.beta.tools.messages.create(\n",
    "    model=\"claude-3-opus-20240229\",\n",
    "    max_tokens=1024,\n",
    "    tools=composio_tools,\n",
    "    messages=[{\"role\": \"user\", \"content\": \"Star me composiohq/composio repo in github.\"}],\n",
    ")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'execution_details': {'executed': True}, 'response_data': ''}]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "toolset.handle_tool_calls(llm_response=response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    }
   ],
   "source": [
    "print(response.content.__len__())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<thinking>\n",
      "The get_weather tool seems most relevant to answer this request about the weather in a specific location. It requires one parameter:\n",
      "\n",
      "location: The user provided this - \"San Francisco\". \n",
      "\n",
      "Since the required parameter is provided, we can call the tool to get the current weather for San Francisco.\n",
      "</thinking>\n"
     ]
    }
   ],
   "source": [
    "print(response.content[0].text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "get_weather\n"
     ]
    }
   ],
   "source": [
    "print(response.content[1].name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'location': 'San Francisco, CA'}\n"
     ]
    }
   ],
   "source": [
    "from anthropic.types.beta.tools import ToolUseBlock\n",
    "\n",
    "for content in response.content:\n",
    "    if isinstance(content, ToolUseBlock):\n",
    "        action_name_to_execute = content.name\n",
    "        arguments = content.input\n",
    "es"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'ChatCompletion' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[36], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mhandle_tool_calls\u001b[39m(\u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m----> 2\u001b[0m                       llm_response: \u001b[43mChatCompletion\u001b[49m, \n\u001b[1;32m      3\u001b[0m                       entity_id: \u001b[38;5;28mstr\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdefault\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mlist\u001b[39m[\u001b[38;5;28many\u001b[39m]:\n\u001b[1;32m      4\u001b[0m     output \u001b[38;5;241m=\u001b[39m []        \n\u001b[1;32m      5\u001b[0m     entity \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclient\u001b[38;5;241m.\u001b[39msdk\u001b[38;5;241m.\u001b[39mget_entity(entity_id)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'ChatCompletion' is not defined"
     ]
    }
   ],
   "source": [
    "def handle_tool_calls(\n",
    "    self, llm_response: ChatCompletion, entity_id: str = \"default\"\n",
    ") -> list[any]:\n",
    "    output = []\n",
    "    entity = self.client.sdk.get_entity(entity_id)\n",
    "    try:\n",
    "        if llm_response.choices:\n",
    "            for choice in llm_response.choices:\n",
    "                if choice.message.tool_calls:\n",
    "                    for tool_call in choice.message.tool_calls:\n",
    "                        action_name_to_execute = tool_call.function.name\n",
    "                        action = self.client.sdk.get_action_enum_without_tool(\n",
    "                            action_name=action_name_to_execute\n",
    "                        )\n",
    "                        arguments = json.loads(tool_call.function.arguments)\n",
    "                        account = entity.get_connection(app_name=action.service)\n",
    "                        output.append(account.execute_action(action, arguments))\n",
    "\n",
    "    except Exception as e:\n",
    "        raise e from e\n",
    "\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'location': 'San Francisco, CA'}\n"
     ]
    }
   ],
   "source": [
    "print(response.content[1].input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ChatCompletion(id='chatcmpl-9Km8DNrJxFM42yy1Xfp4IkzYLqTNU', choices=[Choice(finish_reason='tool_calls', index=0, logprobs=None, message=ChatCompletionMessage(content=None, role='assistant', function_call=None, tool_calls=[ChatCompletionMessageToolCall(id='call_nR01GHOUILL6uprt1KMuYleu', function=Function(arguments='{\"location\": \"San Francisco\", \"unit\": \"celsius\"}', name='get_current_weather'), type='function'), ChatCompletionMessageToolCall(id='call_TQVtvYkLp6HGBU8Gk9XdbuC4', function=Function(arguments='{\"location\": \"Tokyo\", \"unit\": \"celsius\"}', name='get_current_weather'), type='function'), ChatCompletionMessageToolCall(id='call_ik82gT8YyRbKE2ckVcG1rTB4', function=Function(arguments='{\"location\": \"Paris\", \"unit\": \"celsius\"}', name='get_current_weather'), type='function')]))], created=1714738605, model='gpt-3.5-turbo-0125', object='chat.completion', system_fingerprint='fp_3b956da36b', usage=CompletionUsage(completion_tokens=77, prompt_tokens=88, total_tokens=165))\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import dotenv\n",
    "from pprint import pprint\n",
    "from openai import OpenAI\n",
    "from composio_openai import App, ComposioToolset\n",
    "\n",
    "\n",
    "# Loading the variables from .env file\n",
    "dotenv.load_dotenv()\n",
    "\n",
    "client = OpenAI()\n",
    "\n",
    "\n",
    "# Example dummy function hard coded to return the same weather\n",
    "# In production, this could be your backend API or an external API\n",
    "def get_current_weather(location, unit=\"fahrenheit\"):\n",
    "    \"\"\"Get the current weather in a given location\"\"\"\n",
    "    if \"tokyo\" in location.lower():\n",
    "        return json.dumps({\"location\": \"Tokyo\", \"temperature\": \"10\", \"unit\": unit})\n",
    "    elif \"san francisco\" in location.lower():\n",
    "        return json.dumps(\n",
    "            {\"location\": \"San Francisco\", \"temperature\": \"72\", \"unit\": unit}\n",
    "        )\n",
    "    elif \"paris\" in location.lower():\n",
    "        return json.dumps({\"location\": \"Paris\", \"temperature\": \"22\", \"unit\": unit})\n",
    "    else:\n",
    "        return json.dumps({\"location\": location, \"temperature\": \"unknown\"})\n",
    "\n",
    "\n",
    "tools = [\n",
    "    {\n",
    "        \"type\": \"function\",\n",
    "        \"function\": {\n",
    "            \"name\": \"get_current_weather\",\n",
    "            \"description\": \"Get the current weather in a given location\",\n",
    "            \"parameters\": {\n",
    "                \"type\": \"object\",\n",
    "                \"properties\": {\n",
    "                    \"location\": {\n",
    "                        \"type\": \"string\",\n",
    "                        \"description\": \"The city and state, e.g. San Francisco, CA\",\n",
    "                    },\n",
    "                    \"unit\": {\"type\": \"string\", \"enum\": [\"celsius\", \"fahrenheit\"]},\n",
    "                },\n",
    "                \"required\": [\"location\"],\n",
    "            },\n",
    "        },\n",
    "    }\n",
    "]\n",
    "response = client.chat.completions.create(\n",
    "    model=\"gpt-3.5-turbo-0125\",\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": \"What's the weather like in San Francisco, Tokyo, and Paris?\",\n",
    "        }\n",
    "    ],\n",
    "    tools=tools,\n",
    "    tool_choice=\"auto\",  # auto is default, but we'll be explicit\n",
    ")\n",
    "\n",
    "pprint(response)\n",
    "\n",
    "# result = toolset.handle_tool_calls(response)\n",
    "# pprint(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "print(response.choices[0].message.function_call)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ChatCompletionMessageToolCall(id='call_nR01GHOUILL6uprt1KMuYleu', function=Function(arguments='{\"location\": \"San Francisco\", \"unit\": \"celsius\"}', name='get_current_weather'), type='function'), ChatCompletionMessageToolCall(id='call_TQVtvYkLp6HGBU8Gk9XdbuC4', function=Function(arguments='{\"location\": \"Tokyo\", \"unit\": \"celsius\"}', name='get_current_weather'), type='function'), ChatCompletionMessageToolCall(id='call_ik82gT8YyRbKE2ckVcG1rTB4', function=Function(arguments='{\"location\": \"Paris\", \"unit\": \"celsius\"}', name='get_current_weather'), type='function')]\n"
     ]
    }
   ],
   "source": [
    "print(response.choices[0].message.tool_calls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "composio-trial",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
